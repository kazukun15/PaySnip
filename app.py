import streamlit as st
import pandas as pd
import io
import zipfile
import re
import time
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from pypdf import PdfReader, PdfWriter
import google.generativeai as genai
from google.api_core.exceptions import InternalServerError

# â”€â”€ Streamlit è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="æ”¯æ‰•é€šçŸ¥æ›¸æŠ½å‡ºãƒ„ãƒ¼ãƒ«", layout="wide")
st.title("ğŸ“„ æ”¯æ‰•é€šçŸ¥æ›¸æŠ½å‡ºãƒ„ãƒ¼ãƒ«")

# â”€â”€ ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ•ã‚¡ã‚¤ãƒ«é¸æŠãƒ»è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.header("1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
pdf_file = st.sidebar.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ« (.pdf)", type="pdf")
csv_file = st.sidebar.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ« (.csv)", type="csv")

st.sidebar.header("2. ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
enable_refine = st.sidebar.checkbox("Gemini è£œæ­£ã‚’æœ‰åŠ¹ã«ã™ã‚‹", value=False)

action_preview = st.sidebar.button("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œ")
action_extract = st.sidebar.button("æŠ½å‡ºå®Ÿè¡Œ")

# â”€â”€ Gemini ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def init_gemini_model(api_key: str) -> Optional[genai.GenerativeModel]:
    if not api_key:
        return None
    genai.configure(api_key=api_key)
    try:
        return genai.GenerativeModel('gemini-2.5-flash-preview-04-17')
    except Exception:
        return None

gemini_api_key = st.secrets.get("gemini", {}).get("api_key", "")
model = init_gemini_model(gemini_api_key)

# â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_text(text: str) -> str:
    """ç©ºç™½é™¤å»ã—ã¦æ¯”è¼ƒã—ã‚„ã™ãã™ã‚‹"""
    return re.sub(r"\s+", "", text)

def refine_text(raw: str, page: int) -> str:
    """Gemini APIã§èª¤ã‚Šã‚’è£œæ­£ï¼ˆAPIã‚¨ãƒ©ãƒ¼ãªã‚‰ç”Ÿãƒ†ã‚­ã‚¹ãƒˆè¿”å´ï¼‰"""
    if not (model and enable_refine):
        return raw
    try:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒãƒƒã‚¯ãƒ†ã‚£ãƒƒã‚¯ã‚’å«ã‚ãšã€ã‚·ãƒ³ãƒ—ãƒ«ãªæ–‡ç« å½¢å¼ã«å¤‰æ›´ã—ã¦f-stringã‚¨ãƒ©ãƒ¼å›é¿
        prompt = f"""PDFã®{page}ãƒšãƒ¼ã‚¸ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸæ”¯æ‰•é€šçŸ¥æ›¸ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€èª¤å­—è„±å­—ãªãè‡ªç„¶ãªæ—¥æœ¬èªã«ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

{raw}
"""
        res = model.generate_content(prompt)
        return res.text
    except InternalServerError:
        return raw
    except Exception:
        return raw

# â”€â”€ ãƒãƒƒãƒãƒ³ã‚°å‡¦ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def find_matches(
    reader: PdfReader,
    names: List[str],
    accounts: List[str],
) -> List[Dict]:
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ â†’ è£œæ­£ â†’ åå‰ or å£åº§ç•ªå·ã§ãƒãƒƒãƒ"""
    results = []
    total = len(reader.pages)
    for idx in range(total):
        raw = reader.pages[idx].extract_text() or ""
        text = raw
        # è£œæ­£ãƒ†ã‚­ã‚¹ãƒˆ
        if enable_refine:
            text = refine_text(raw, idx+1)
        norm = normalize_text(text)
        matched: Optional[str] = None
        # åå‰å„ªå…ˆ
        for name in names:
            if normalize_text(name) in norm:
                matched = name
                break
        # å£åº§ç•ªå·è£œåŠ©
        if not matched:
            digits = re.sub(r"\D", "", text)
            for acc in accounts:
                if re.sub(r"\D", "", acc) in digits:
                    matched = acc
                    break
        if matched:
            results.append({"page": idx+1, "match": matched})
    return results

# â”€â”€ ã‚¢ãƒ—ãƒªæœ¬ä½“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not pdf_file or not csv_file:
    st.warning("PDFã¨CSVã‚’ä¸¡æ–¹ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
csv_df = load_csv(csv_file)
pdf_reader = load_pdf_reader(pdf_file)
names = csv_df.get("ç›¸æ‰‹æ–¹", pd.Series()).dropna().str.strip().tolist()
accounts = sum([csv_df.get(c, pd.Series()).dropna().str.strip().tolist()
                for c in ["å£åº§ç•ªå·ï¼‘","å£åº§ç•ªå·ï¼’","å£åº§ç•ªå·ï¼“"]], [])

st.subheader("CSV ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
st.dataframe(csv_df.head(5))
st.write(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰PDFãƒšãƒ¼ã‚¸æ•°: {len(pdf_reader.pages)} ãƒšãƒ¼ã‚¸")

# ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
if action_preview:
    with st.spinner("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œä¸­â€¦"):
        t0 = time.time()
        preview = find_matches(pdf_reader, names, accounts)
        dt = time.time() - t0
    st.success(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Œäº† ({dt:.2f}ç§’)")
    if preview:
        st.table(pd.DataFrame(preview))
    else:
        st.warning("ä¸€è‡´ã™ã‚‹ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# æŠ½å‡º
if action_extract:
    with st.spinner("æŠ½å‡ºå®Ÿè¡Œä¸­â€¦"):
        t0 = time.time()
        matches = find_matches(pdf_reader, names, accounts)
        # ZIPä½œæˆ
        buf = io.BytesIO()
        with zipfile.ZipFile(buf, 'w', zipfile.ZIP_DEFLATED) as zf:
            for m in matches:
                page = m['page'] - 1
                writer = PdfWriter()
                writer.add_page(pdf_reader.pages[page])
                b = io.BytesIO()
                writer.write(b)
                safe = re.sub(r"[\\/:*?\"<>|]", "_", m['match'])
                fname = f"{datetime.now():%Y%m%d}_æ”¯æ‰•é€šçŸ¥æ›¸_{safe}_p{m['page']}.pdf"
                zf.writestr(fname, b.getvalue())
        buf.seek(0)
        dt = time.time() - t0
    if matches:
        st.success(f"æŠ½å‡ºå®Œäº† ({dt:.2f}ç§’) - {len(matches)}ãƒšãƒ¼ã‚¸ã‚’ZIPåŒ–ã—ã¾ã—ãŸã€‚")
        st.download_button(
            "ZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", buf,
            file_name=f"{datetime.now():%Y%m%d}_æ”¯æ‰•é€šçŸ¥æ›¸.zip"
        )
        st.subheader("æŠ½å‡ºçµæœè©³ç´°")
        st.dataframe(pd.DataFrame(matches))
    else:
        st.warning(f"æŠ½å‡ºå¯¾è±¡ã®ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ ({dt:.2f}ç§’)")
