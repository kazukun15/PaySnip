import streamlit as st
import pandas as pd
import io
import zipfile
import re
import time
from datetime import datetime
from pypdf import PdfReader, PdfWriter
import google.generativeai as genai
from google.api_core.exceptions import InternalServerError
from st_aggrid import AgGrid, GridOptionsBuilder

# â”€â”€ Streamlit è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="æ”¯æ‰•é€šçŸ¥æ›¸æŠ½å‡ºãƒ„ãƒ¼ãƒ«", layout="wide")
st.title("ğŸ“„ æ”¯æ‰•é€šçŸ¥æ›¸æŠ½å‡ºãƒ„ãƒ¼ãƒ«")

# â”€â”€ ãƒ˜ãƒ«ãƒ—ï¼ä½¿ã„æ–¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.header("ğŸ†˜ ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰")
st.sidebar.markdown(
    """
    1. å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰PDFã¨CSVã‚’é¸æŠ
    2. è‡ªå‹•ã§ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
    3. ã‚¨ãƒ©ãƒ¼ãŒãªã‘ã‚Œã°æŠ½å‡ºãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„
    4. ZIPå½¢å¼ã§æ”¯æ‰•é€šçŸ¥æ›¸ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™
    """
)

# â”€â”€ ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
pdf_file = st.sidebar.file_uploader("ğŸ“ PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="pdf", key="pdf_uploader")
csv_file = st.sidebar.file_uploader("ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="csv", key="csv_uploader")

# â”€â”€ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿æŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if 'pdf_bytes' not in st.session_state and pdf_file:
    st.session_state['pdf_bytes'] = pdf_file.read()
if 'csv_bytes' not in st.session_state and csv_file:
    st.session_state['csv_bytes'] = csv_file.read()

# â”€â”€ Google Gemini åˆæœŸåŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
gemini_api_key = st.secrets.get("gemini_api_key", "")
model = None
if gemini_api_key:
    genai.configure(api_key=gemini_api_key)
    try:
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
    except Exception as e:
        st.sidebar.error(f"GeminiåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

# â”€â”€ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãèª­ã¿è¾¼ã¿é–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data
def load_csv(bytes_data: bytes) -> pd.DataFrame:
    for enc in ("utf-8", "cp932", "shift_jis"):  
        try:
            return pd.read_csv(io.BytesIO(bytes_data), dtype=str, encoding=enc)
        except Exception:
            continue
    raise ValueError("CSVèª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

@st.cache_data
def load_pdf(bytes_data: bytes) -> PdfReader:
    reader = PdfReader(io.BytesIO(bytes_data))
    if not reader.pages:
        raise ValueError("PDFã«ãƒšãƒ¼ã‚¸ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    return reader

# â”€â”€ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if 'pdf_bytes' not in st.session_state or 'csv_bytes' not in st.session_state:
    st.info("PDFã¨CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨è‡ªå‹•ã§ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¾ã™ã€‚")
    st.stop()

# â”€â”€ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒ¼ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    df_csv = load_csv(st.session_state['csv_bytes'])
    reader = load_pdf(st.session_state['pdf_bytes'])
except Exception as e:
    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# â”€â”€ CSVãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆAgGridï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("CSVãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
gb = GridOptionsBuilder.from_dataframe(df_csv)
gb.configure_pagination(paginationAutoPageSize=True)
gb.configure_default_column(filterable=True, sortable=True)
AgGrid(df_csv, gridOptions=gb.build(), height=300)

# â”€â”€ å…±é€šé–¢æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_text(text: str) -> str:
    return re.sub(r"\s+", "", text)

# ãƒ¢ãƒ‡ãƒ«è£œæ­£é–¢æ•°çœç•¥ï¼ˆå¿…è¦ã«å¿œã˜å†å®šç¾©ï¼‰

# â”€â”€ ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def match_pages(reader, names_map, accounts_map, use_refine=False):
    results = []
    total = len(reader.pages)
    for i, page in enumerate(reader.pages, start=1):
        st.progress(i/total)
        raw = page.extract_text() or ""
        norm = normalize_text(raw)
        # åå‰å„ªå…ˆ
        matched = None
        for k,v in names_map.items():
            if k in norm:
                matched = v
                break
        if not matched:
            digits = re.sub(r"\D", "", norm)
            for k,v in accounts_map.items():
                if k in digits:
                    matched = v
                    break
        if matched:
            results.append((i, matched))
    return results

# â”€â”€ ãƒãƒƒãƒ—ç”Ÿæˆâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
raw_names = df_csv['ç›¸æ‰‹æ–¹'].dropna().tolist()
names_map = {normalize_text(n): n for n in raw_names}
raw_accounts = []
for col in ['å£åº§ç•ªå·ï¼‘','å£åº§ç•ªå·ï¼’','å£åº§ç•ªå·ï¼“']:
    raw_accounts += df_csv.get(col, pd.Series()).dropna().tolist()
accounts_map = {re.sub(r"\D","",a):a for a in raw_accounts}

# â”€â”€ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœè¡¨ç¤ºâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœï¼ˆè‡ªå‹•ãƒãƒƒãƒãƒ³ã‚°ï¼‰")
preview = match_pages(reader, names_map, accounts_map)
if preview:
    st.table(pd.DataFrame(preview, columns=['ãƒšãƒ¼ã‚¸','ãƒãƒƒãƒ']))
else:
    st.warning("ä¸€è‡´ã™ã‚‹ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# â”€â”€ æŠ½å‡ºãƒœã‚¿ãƒ³â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("æŠ½å‡ºå®Ÿè¡Œ", use_container_width=True):
    start = time.time()
    matches = match_pages(reader, names_map, accounts_map)
    if not matches:
        st.error("æŠ½å‡ºå¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        buf = io.BytesIO()
        with zipfile.ZipFile(buf,'w') as zf:
            for pg, key in matches:
                writer = PdfWriter()
                writer.add_page(reader.pages[pg-1])
                fbuf = io.BytesIO()
                writer.write(fbuf)
                fname = f"{datetime.now():%Y%m%d}_æ”¯æ‰•é€šçŸ¥æ›¸_{key}_p{pg}.pdf"
                zf.writestr(fname, fbuf.getvalue())
        buf.seek(0)
        st.download_button("ZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=buf,
                           file_name=f"{datetime.now():%Y%m%d}_æ”¯æ‰•é€šçŸ¥æ›¸.zip",
                           mime="application/zip")
        st.success(f"å®Œäº†: {len(matches)} ä»¶ ({time.time()-start:.2f}ç§’)")
